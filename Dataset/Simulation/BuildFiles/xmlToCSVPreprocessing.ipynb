{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e2df528b",
   "metadata": {},
   "source": [
    "# Data Preprocessing for Synthetic Multi-Entity Multivariate Time-Series\n",
    "\n",
    "**Author:** Bahar\n",
    "\n",
    "This notebook demonstrates the preprocessing workflow for our **synthetic multi-entity time-series datasets** generated using the simulation in the Unity Environment.  \n",
    "\n",
    "\n",
    "The steps include:  \n",
    "\n",
    "1. **XML to CSV**  \n",
    "   - Optional: Check Exported XML Files per Subfolder\n",
    "       - In rare cases, some agents may not have any exported XML files.  \n",
    "       - This step detects such cases and allows you to remove incomplete agents before preprocessing.\n",
    "   - Save as CSV\n",
    "   - Round Time\n",
    "   \n",
    "3. **Add Acceleration Using Savitzky–Golay Filter (SciPy)**  \n",
    "   - Use `savgol_filter` with the second derivative to calculate acceleration.  \n",
    "   \n",
    "2. **Optional: Rename Files** \n",
    "\n",
    "> ⚠️ Notes  \n",
    "\n",
    "        1. Some steps are optional and meant to help clean and standardize the data before further analysis.  \n",
    "        2. Number of Agents in Train Station Waiting Area simulation is 20, and bi-directional Corridor Collision is 30.  \n",
    "        3. Sampling Rate = 10 Hz.\n",
    "\n",
    "**Tip:** The code is provided as a starting point and \"as is\"—you are welcome to optimize or adapt it as desired."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cdb2f16",
   "metadata": {},
   "source": [
    "## Importing the required libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b038aefd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import glob\n",
    "import os\n",
    "import csv\n",
    "import re\n",
    "import math\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os import listdir, path\n",
    "import xml.etree.ElementTree as ET\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.interpolate import CubicSpline\n",
    "from scipy.signal import medfilt\n",
    "from scipy import signal\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30ea9ed0",
   "metadata": {},
   "outputs": [],
   "source": [
    "root_path = r'C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML'\n",
    "Num_agents = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64a09d55",
   "metadata": {},
   "source": [
    "## Remove the wrapper files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f30431c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Removing unwanted xml files\n",
    "pattern = os.path.join (root_path, \"**\", \"wrapper-*\")\n",
    "fileList = glob.glob(pattern, recursive=True)\n",
    "# Iterate over the list of filepaths & remove each file.\n",
    "for filePath in fileList:\n",
    "    try:\n",
    "        os.remove(filePath)\n",
    "    except OSError:\n",
    "        print(\"Error while deleting file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f4e9273",
   "metadata": {},
   "source": [
    "## Optional: Check Exported XML Files per Subfolder  \n",
    "\n",
    "In rare cases, an agent may not have any exported XML files.  \n",
    "You can detect such cases and remove those agents before preprocessing.  \n",
    "\n",
    "- This step is optional.  \n",
    "- Useful for ensuring that each agent has valid data before further processing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "db165c6c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of subfolders with less than 20 XML files: 0\n"
     ]
    }
   ],
   "source": [
    "def count_subfolders_with_few_xml_files(parent_folder):\n",
    "    # Initialize the counter\n",
    "    subfolder_count_with_few_files = 0 \n",
    "\n",
    "    for subfolder in os.listdir(parent_folder):\n",
    "        subfolder_path = os.path.join(parent_folder, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            xml_files = [f for f in os.listdir(subfolder_path) if f.endswith('.xml')]\n",
    "            if len(xml_files) < Num_agents:\n",
    "                subfolder_count_with_few_files += 1 \n",
    "\n",
    "    # Print the total count\n",
    "    print(f'Total number of subfolders with less than 20 XML files: {subfolder_count_with_few_files}')  \n",
    "\n",
    "count_subfolders_with_few_xml_files(root_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50fa036c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def move_subfolders_with_few_xml_files(parent_folder, destination_folder):\n",
    "    # Ensure the destination folder exists\n",
    "    os.makedirs(destination_folder, exist_ok=True)\n",
    "    \n",
    "    # Initialize the counter\n",
    "    subfolder_count_with_few_files = 0\n",
    "\n",
    "    for subfolder in os.listdir(parent_folder):\n",
    "        subfolder_path = os.path.join(parent_folder, subfolder)\n",
    "        if os.path.isdir(subfolder_path):\n",
    "            xml_files = [f for f in os.listdir(subfolder_path) if f.endswith('.xml')]\n",
    "            if len(xml_files) < Num_agents:\n",
    "                subfolder_count_with_few_files += 1\n",
    "                \n",
    "                # Move the subfolder to the destination folder\n",
    "                shutil.move(subfolder_path, os.path.join(destination_folder, subfolder))\n",
    "\n",
    "    print(f'Total number of subfolders with less than 20 XML files moved: {subfolder_count_with_few_files}')\n",
    "\n",
    "destination_folder_path = r'pathTo\\lessThan'\n",
    "move_subfolders_with_few_xml_files(root_path, destination_folder_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e621c22",
   "metadata": {},
   "source": [
    "## Save XML files as CSV file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f3544738",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subdir, dirs, files in os.walk(root_path):\n",
    "    t=1;\n",
    "    for file in files:\n",
    "        if file.endswith('.xml'):\n",
    "            # Read the contents of the XML file\n",
    "            xml_file_path = os.path.join(subdir, file)\n",
    "            cols = [\"PX\", \"PY\", \"PZ\", \"RX\", \"RY\", \"RZ\",\"runTime\",\"AgentID\"]\n",
    "            rows = []\n",
    "            try:\n",
    "                xmlparse= ET.parse(xml_file_path)\n",
    "\n",
    "                root = xmlparse.getroot()\n",
    "\n",
    "                for i in root:\n",
    "                    runTime= i.attrib['runningTime']\n",
    "                    PX = i.find(\"PX\").text\n",
    "                    PY = i.find(\"PY\").text\n",
    "                    PZ = i.find(\"PZ\").text\n",
    "                    RX = i.find(\"RX\").text\n",
    "                    RY = i.find(\"RY\").text\n",
    "                    RZ = i.find(\"RZ\").text\n",
    "                    AgentID= t\n",
    "\n",
    "                    rows.append({\"PX\": PX,\n",
    "                        \"PY\": PY,\n",
    "                        \"PZ\": PZ,\n",
    "                        \"RX\": RX,\n",
    "                        \"RY\": RY,\n",
    "                        \"RZ\": RZ,\n",
    "                        \"runTime\": runTime,\n",
    "                        \"AgentID\":AgentID})\n",
    "                df = pd.DataFrame(rows, columns=cols)\n",
    "                df_new= df.drop_duplicates(subset='runTime', keep=\"last\")\n",
    "\n",
    "                with open (xml_file_path+'.csv', 'w', newline='') as result:\n",
    "                    df_new.to_csv(result, index=False)\n",
    "                    t=t+1\n",
    "            except:\n",
    "                pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9ff8eba",
   "metadata": {},
   "source": [
    "## Removing XML files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "90317286",
   "metadata": {},
   "outputs": [],
   "source": [
    "pattern = os.path.join (root_path, \"**\", \"*.xml\")\n",
    "fileList = glob.glob(pattern, recursive=True)\n",
    "\n",
    "for filePath in fileList:\n",
    "    try:\n",
    "        os.remove(filePath)\n",
    "    except OSError:\n",
    "        print(\"Error while deleting file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bb47235",
   "metadata": {},
   "source": [
    "## Rounding the time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e62d248",
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(root_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            filename = os.path.join(root, file)\n",
    "            df = pd.read_csv(filename)\n",
    "            # Create a new column that rounds down each value using math.floor()\n",
    "            df.loc[0, \"t\"] = math.floor(df.loc[0, \"runTime\"]*10)/10\n",
    "            for i in range(df[\"runTime\"].count()-1):\n",
    "                df.loc[i+1, \"t\"] = df.loc[i, \"t\"] + 0.1\n",
    "\n",
    "            # Write the updated DataFrame back to the CSV file\n",
    "            df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "7383088b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for root, dirs, files in os.walk(root_path):\n",
    "    for file in files:\n",
    "        if file.endswith(\".csv\"):\n",
    "            filename = os.path.join(root, file)\n",
    "            df = pd.read_csv(filename)\n",
    "            df['t'] = df['t'].round(1)\n",
    "\n",
    "            df.to_csv(filename, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da37f89",
   "metadata": {},
   "source": [
    "# Add Acceleration Using Savitzky–Golay Filter (SciPy)\n",
    "\n",
    "**Notes:**\n",
    "- We use `scipy.signal.savgol_filter` with the *second derivative* to calculate acceleration.  \n",
    "- This filter produces smoother and more accurate results in our tests.  \n",
    "- Others are welcome to experiment with different methods for calculating acceleration."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "02d46837",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subdir, dirs, files in os.walk(root_path):\n",
    "    for file in files:\n",
    "        if file.endswith('.csv'):\n",
    "            # Read the csv files\n",
    "            csv_file_path = os.path.join(subdir, file)\n",
    "            df = pd.read_csv(csv_file_path)\n",
    "\n",
    "            x = df['PX'].values\n",
    "            y = df['PY'].values\n",
    "            z = df['PZ'].values\n",
    "\n",
    "            rx = df['RX'].values\n",
    "            ry = df['RY'].values\n",
    "            rz = df['RZ'].values\n",
    "\n",
    "            t = df['t'].values\n",
    "            ID= df['AgentID'].values\n",
    "\n",
    "            # Calculate the acceleration based on the savgol_filter\n",
    "            dt = 0.1\n",
    "            ax= signal.savgol_filter(x, window_length=21, polyorder=3, deriv=2, delta=dt, mode=\"nearest\")\n",
    "            ay= signal.savgol_filter(y, window_length=21, polyorder=3, deriv=2, delta=dt, mode=\"nearest\")\n",
    "            az= signal.savgol_filter(z, window_length=21, polyorder=3, deriv=2, delta=dt, mode=\"nearest\")\n",
    "\n",
    "            # Save to a new CSV file\n",
    "            filtered_data = pd.DataFrame({\n",
    "                                  't': t,\n",
    "                                  'x': x,\n",
    "                                  'y': y,\n",
    "                                  'z': z,\n",
    "                                  'ax': ax,\n",
    "                                  'ay': ay,\n",
    "                                  'az': az,\n",
    "                                  'rx':rx,\n",
    "                                  'ry':ry,\n",
    "                                  'rz':rz,\n",
    "                                  'ID': ID})\n",
    "\n",
    "            filtered_data.to_csv(csv_file_path, index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b07ed41",
   "metadata": {},
   "source": [
    "## Optional: Rename Files  \n",
    "\n",
    "You may optionally rename the files (e.g., based on `agent_id`) to make them easier to work with during preprocessing.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d03bc18b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Renamed: C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\log-45909.4175649769.xml.csv -> C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\Agent_1.csv\n",
      "Renamed: C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\log-45909.4175660417.xml.csv -> C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\Agent_2.csv\n",
      "Renamed: C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\log-45909.4175671528.xml.csv -> C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\Agent_3.csv\n",
      "Renamed: C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\log-45909.4175677894.xml.csv -> C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\Agent_4.csv\n",
      "Renamed: C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\log-45909.4175691435.xml.csv -> C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\Agent_5.csv\n",
      "Renamed: C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\log-45909.4175696644.xml.csv -> C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\Agent_6.csv\n",
      "Renamed: C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\log-45909.4175702546.xml.csv -> C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\Agent_7.csv\n",
      "Renamed: C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\log-45909.4175710301.xml.csv -> C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\Agent_8.csv\n",
      "Renamed: C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\log-45909.4175715972.xml.csv -> C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\Agent_9.csv\n",
      "Renamed: C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\log-45909.4175735185.xml.csv -> C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\Agent_10.csv\n",
      "Renamed: C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\log-45909.4175743056.xml.csv -> C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\Agent_11.csv\n",
      "Renamed: C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\log-45909.4175748727.xml.csv -> C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\Agent_12.csv\n",
      "Renamed: C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\log-45909.4175758102.xml.csv -> C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\Agent_13.csv\n",
      "Renamed: C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\log-45909.4175766319.xml.csv -> C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\Agent_14.csv\n",
      "Renamed: C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\log-45909.4175776389.xml.csv -> C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\Agent_15.csv\n",
      "Renamed: C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\log-45909.4175784144.xml.csv -> C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\Agent_16.csv\n",
      "Renamed: C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\log-45909.4175793287.xml.csv -> C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\Agent_17.csv\n",
      "Renamed: C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\log-45909.4175799306.xml.csv -> C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\Agent_18.csv\n",
      "Renamed: C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\log-45909.4175806713.xml.csv -> C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\Agent_19.csv\n",
      "Renamed: C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\log-45909.4175814931.xml.csv -> C:\\myDrive\\TuftsPhD2022\\ProfMillerPhDResearch\\PhDResearchProfMiller\\Github-Official\\BuildFiles_V2_CorrectxML\\MyOutput0\\Agent_20.csv\n"
     ]
    }
   ],
   "source": [
    "csv_files = glob.glob(os.path.join(root_path, \"**\", \"*.csv\"), recursive=True)\n",
    "\n",
    "for file in csv_files:\n",
    "    try:\n",
    "        # Read the Agent ID\n",
    "        df = pd.read_csv(file, usecols=[\"ID\"])\n",
    "        agent_id = str(df[\"ID\"].iloc[0])\n",
    "        \n",
    "        # new file path naming\n",
    "        folder = os.path.dirname(file)\n",
    "        new_name = f\"Agent_{agent_id}.csv\"\n",
    "        new_path = os.path.join(folder, new_name)\n",
    "        \n",
    "        # Rename\n",
    "        os.rename(file, new_path)\n",
    "        print(f\"Renamed: {file} -> {new_path}\")\n",
    "    \n",
    "    except Exception as e:\n",
    "        print(f\"Skipping {file} due to error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da38dcb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
